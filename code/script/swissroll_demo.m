% This script is for demonstrating how to run LL-LVM on the Swiss roll data.
% - mijung wrote on 12th of nov, 2015
% - Wittawat simplified it on 13 Nov 2015

clear;
data_flag = 3; % swiss roll
% n: Number of data points to generate.
n = 400; 
% k: k in the k-nearest-neighbours graph construction
k = 8;

% maximum number of EM iterations to perform
% In practice, we might need more iterations.
% If you want to get better results, try to increase this and reduce 
% the abs_tol (absolute tolerance threshold for convergence check) below.
max_em_iter = 50;

% random seed. This will affect the initializations of LLLVM.
seednum = 3;
oldRng = rng();
rng(seednum);

% generate artificial data. Many artificial datasets can be generated by 
% changing data_flag.
[n, dy, Y, G, dmat, col, truex] = getartificial(n, data_flag, k);

% Construct a neighbourhood graph with kNN
Y = reshape(Y, dy, n);
G = makeKnnG(Y, k);
dx = 2;

h = sum(G, 2);
L = diag(h) - G;
if rank(L)< n-1
    display('sorry, choose a larger k so that rank(L)=n-1');
    break;
end

% options to lllvm_1ep. Include initializations
% Most options are optional. See lllvm_1ep file directly for possible options.
op = struct();
op.seed = seednum;
op.max_em_iter = max_em_iter;
% absolute tolerance of the increase of the likelihood.
% If (like_i - like_{i-1} )  < abs_tol, stop EM.
op.abs_tol = 1e-3;
op.G = G;
op.dx = dx;
% The factor to be added to the prior covariance of C and likelihood. This must
% be positive and typically small.
op.epsilon = 1e-3;
% Intial value of alpha. Alpha appears in precision in the prior for x (low
% dimensional latent). This will be optimized in M steps.
op.alpha0 = 1;
% initial value of gamma.  V^-1 = gamma*I_dy where V is the covariance in the
% likelihood of  the observations Y.
op.gamma0 = 1;

% initial value of the posterior mean and cov of c. (optional)
% If not set, they will be initialized automatically.
%
op.cov_c0 = kron(ones(n, n), eye(dx) );
%op.cov_c0 = eye(n*dx);
op.mean_c0 = rand(dy, dx*n);
%
%op.cov_c0 = inv(op.epsilon*(J*J') + invOmega) ;
%op.mean_c0 = randn(dy, dx*n)*op.cov_c0';

% Call lllvm_1ep to run LL-LVM.
% Relevant variances are in the struct "results".
[results, op ] = lllvm_1ep(Y, op);

% An example of how to save the results. 
fname = sprintf('swissdemo_s%d_n%d_k%d.mat', seednum, n, k);
save(fname, 'results', 'Y', 'col', 'truex');

%% visualise results
load(fname); 
figure(3);
% This is the relative size to plot the tangent planes.
tangent_scale = 0.15;
% Plot the data in the orignal space (3d) with learned tangent planes.
% The function plotlearning is specific to the swiss roll data.
plotlearning(dx,dy,n,reshape(results.mean_c(:,end),dy,n*dx), ...
    Y, col, tangent_scale);

figure;
% plot lower bounds
subplot(211); 
set(gca, 'FontSize', 14);
plot(results.lwbs);
grid on;
xlabel('EM iterations');
ylabel('Evidence lower bounds');

% plot dimensionally reduced points
reshaped_mean_x = reshape(results.mean_x(:,end), dx, []);
subplot(212); 
scatter(reshaped_mean_x(1,:), reshaped_mean_x(2,:), 20, col, 'o', 'filled', 'linewidth', 2);
set(gca, 'FontSize', 14);
title('Dimensionally reduced points (from dy=3 to dx=2).')
xlabel('x');
ylabel('y');

% change seed back
rng(oldRng);


